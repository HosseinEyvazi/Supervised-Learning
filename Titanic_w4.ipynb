{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 3136,
          "databundleVersionId": 26502,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Titanic w4",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HosseinEyvazi/Supervised-Learning/blob/main/Titanic_w4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "8XKNHJv4BsRA"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "titanic_path = kagglehub.competition_download('titanic')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "jq2-5NwuBsRI"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:57.310076Z",
          "iopub.execute_input": "2025-01-09T19:34:57.310421Z",
          "iopub.status.idle": "2025-01-09T19:34:57.320264Z",
          "shell.execute_reply.started": "2025-01-09T19:34:57.310389Z",
          "shell.execute_reply": "2025-01-09T19:34:57.319513Z"
        },
        "id": "8hyDLmwgBsRL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "Hxvp-C12BsRO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler , OneHotEncoder , LabelEncoder , power_transform , QuantileTransformer\n",
        "from sklearn.model_selection import train_test_split , RandomizedSearchCV , GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:57.321755Z",
          "iopub.execute_input": "2025-01-09T19:34:57.322008Z",
          "iopub.status.idle": "2025-01-09T19:34:57.331067Z",
          "shell.execute_reply.started": "2025-01-09T19:34:57.321987Z",
          "shell.execute_reply": "2025-01-09T19:34:57.330236Z"
        },
        "_kg_hide-input": true,
        "id": "BY5TDowUBsRR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Data load and Understanding\n"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "id": "g1haKtK5BsRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
        "test_data = pd.read_csv('/kaggle/input/titanic/test.csv')\n",
        "train_data.head()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:57.332862Z",
          "iopub.execute_input": "2025-01-09T19:34:57.333102Z",
          "iopub.status.idle": "2025-01-09T19:34:57.362945Z",
          "shell.execute_reply.started": "2025-01-09T19:34:57.333082Z",
          "shell.execute_reply": "2025-01-09T19:34:57.362134Z"
        },
        "id": "_wHOYnuXBsRT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.shape\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:57.364478Z",
          "iopub.execute_input": "2025-01-09T19:34:57.364742Z",
          "iopub.status.idle": "2025-01-09T19:34:57.369081Z",
          "shell.execute_reply.started": "2025-01-09T19:34:57.364723Z",
          "shell.execute_reply": "2025-01-09T19:34:57.368433Z"
        },
        "id": "Fi4blG3FBsRV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.isna().sum(axis=0)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:57.463639Z",
          "iopub.execute_input": "2025-01-09T19:34:57.463882Z",
          "iopub.status.idle": "2025-01-09T19:34:57.46979Z",
          "shell.execute_reply.started": "2025-01-09T19:34:57.463861Z",
          "shell.execute_reply": "2025-01-09T19:34:57.469083Z"
        },
        "id": "jbs7evPYBsRW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "correlation = train_data.select_dtypes(include=['number']).corr()\n",
        "sns.heatmap(correlation , annot=True , cmap='coolwarm')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:57.509164Z",
          "iopub.execute_input": "2025-01-09T19:34:57.509395Z",
          "iopub.status.idle": "2025-01-09T19:34:57.928947Z",
          "shell.execute_reply.started": "2025-01-09T19:34:57.509375Z",
          "shell.execute_reply": "2025-01-09T19:34:57.928062Z"
        },
        "id": "nTFZtUobBsRY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.describe()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:57.93028Z",
          "iopub.execute_input": "2025-01-09T19:34:57.930641Z",
          "iopub.status.idle": "2025-01-09T19:34:57.955256Z",
          "shell.execute_reply.started": "2025-01-09T19:34:57.930607Z",
          "shell.execute_reply": "2025-01-09T19:34:57.954634Z"
        },
        "id": "1ojf3mNDBsRZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA"
      ],
      "metadata": {
        "id": "YLRjTMNXBsRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.drop('PassengerId' , axis=1 , inplace =True)\n",
        "test_data.drop('PassengerId' , axis=1 , inplace =True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:58.063185Z",
          "iopub.execute_input": "2025-01-09T19:34:58.063579Z",
          "iopub.status.idle": "2025-01-09T19:34:58.068693Z",
          "shell.execute_reply.started": "2025-01-09T19:34:58.063542Z",
          "shell.execute_reply": "2025-01-09T19:34:58.067809Z"
        },
        "id": "90MvZsE7BsRb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.duplicated().sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:58.069799Z",
          "iopub.execute_input": "2025-01-09T19:34:58.070142Z",
          "iopub.status.idle": "2025-01-09T19:34:58.084816Z",
          "shell.execute_reply.started": "2025-01-09T19:34:58.070108Z",
          "shell.execute_reply": "2025-01-09T19:34:58.083756Z"
        },
        "id": "drxLsdJ2BsRb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Check null values in train data\n",
        "train_data.isna().sum(axis=0)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:58.086538Z",
          "iopub.execute_input": "2025-01-09T19:34:58.086736Z",
          "iopub.status.idle": "2025-01-09T19:34:58.098426Z",
          "shell.execute_reply.started": "2025-01-09T19:34:58.086719Z",
          "shell.execute_reply": "2025-01-09T19:34:58.097616Z"
        },
        "id": "q7MNGZd8BsRc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Check null values in test data\n",
        "test_data.isna().sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:58.099569Z",
          "iopub.execute_input": "2025-01-09T19:34:58.09983Z",
          "iopub.status.idle": "2025-01-09T19:34:58.11096Z",
          "shell.execute_reply.started": "2025-01-09T19:34:58.099799Z",
          "shell.execute_reply": "2025-01-09T19:34:58.110059Z"
        },
        "id": "Achc-4nmBsRd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing and feature engineering"
      ],
      "metadata": {
        "id": "dC5nsLVbBsRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.columns\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:58.111823Z",
          "iopub.execute_input": "2025-01-09T19:34:58.112057Z",
          "iopub.status.idle": "2025-01-09T19:34:58.126855Z",
          "shell.execute_reply.started": "2025-01-09T19:34:58.112036Z",
          "shell.execute_reply": "2025-01-09T19:34:58.126219Z"
        },
        "id": "cLj9YMx-BsRd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "null value handling"
      ],
      "metadata": {
        "id": "NKMLE_FIBsRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.isna().sum())\n",
        "print('-----------------------------')\n",
        "print(test_data.isna().sum())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:58.127673Z",
          "iopub.execute_input": "2025-01-09T19:34:58.127855Z",
          "iopub.status.idle": "2025-01-09T19:34:58.14004Z",
          "shell.execute_reply.started": "2025-01-09T19:34:58.127839Z",
          "shell.execute_reply": "2025-01-09T19:34:58.139367Z"
        },
        "id": "3yMuMU7JBsRe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "important note : df.groupby returns a series"
      ],
      "metadata": {
        "id": "iUy8SkotBsRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.groupby([ 'Pclass' , 'Sex' ])['Fare'].mean().index"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:58.141786Z",
          "iopub.execute_input": "2025-01-09T19:34:58.142017Z",
          "iopub.status.idle": "2025-01-09T19:34:58.155942Z",
          "shell.execute_reply.started": "2025-01-09T19:34:58.141997Z",
          "shell.execute_reply": "2025-01-09T19:34:58.155039Z"
        },
        "id": "paoSPzvqBsRf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Age null handling\n",
        "train_data.Age = train_data.groupby([ 'Pclass' , 'Sex' ])['Age'].transform(lambda x:x.fillna(x.median()))\n",
        "# train_data.groupby([ 'Pclass' , 'Sex' ])['Age'].transform(lambda x:x.fillna(x.mean())) # another way\n",
        "test_data.Age=test_data.groupby([ 'Pclass' , 'Sex' ])['Age'].transform(lambda x:x.fillna(x.median()))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:58.432204Z",
          "iopub.execute_input": "2025-01-09T19:34:58.432515Z",
          "iopub.status.idle": "2025-01-09T19:34:58.448057Z",
          "shell.execute_reply.started": "2025-01-09T19:34:58.432489Z",
          "shell.execute_reply": "2025-01-09T19:34:58.447214Z"
        },
        "id": "EXO1m62oBsRf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Cabin null handling\n",
        "train_data.Cabin = train_data.Cabin.fillna('has not' )\n",
        "train_data.Cabin[train_data['Cabin'] != 'has not'] = 'has'\n",
        "\n",
        "test_data.Cabin = test_data.Cabin.fillna('has not' )\n",
        "test_data.Cabin[test_data['Cabin'] != 'has not'] = 'has'\n",
        "\n",
        "test_data.rename(columns={'Cabin':'Has_Cabin'})\n",
        "train_data.rename(columns={'Cabin':'Has_Cabin'})\n",
        "\n",
        "train_data.drop('Cabin' , axis=1)\n",
        "test_data.drop('Cabin' , axis=1)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:58.449268Z",
          "iopub.execute_input": "2025-01-09T19:34:58.449562Z",
          "iopub.status.idle": "2025-01-09T19:34:58.473217Z",
          "shell.execute_reply.started": "2025-01-09T19:34:58.449541Z",
          "shell.execute_reply": "2025-01-09T19:34:58.472508Z"
        },
        "id": "BZvqGyWzBsRf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data.Embarked.fillna(train_data.Embarked.mode()[0] , inplace=True) #Embarked is categorical column\n",
        "test_data.Embarked.fillna(train_data.Embarked.mode()[0] , inplace=True) #Embarked is categorical column\n",
        "train_data.Embarked.unique()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:58.474683Z",
          "iopub.execute_input": "2025-01-09T19:34:58.474901Z",
          "iopub.status.idle": "2025-01-09T19:34:58.482241Z",
          "shell.execute_reply.started": "2025-01-09T19:34:58.474882Z",
          "shell.execute_reply": "2025-01-09T19:34:58.481462Z"
        },
        "id": "N9MI5TeVBsRg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.Fare.fillna(test_data.Fare.mode()[0] , inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:58.483553Z",
          "iopub.execute_input": "2025-01-09T19:34:58.483883Z",
          "iopub.status.idle": "2025-01-09T19:34:58.49449Z",
          "shell.execute_reply.started": "2025-01-09T19:34:58.48385Z",
          "shell.execute_reply": "2025-01-09T19:34:58.493476Z"
        },
        "id": "2SxjOd18BsRg"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.isna().sum().sum())\n",
        "test_data.isna().sum().sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:58.495533Z",
          "iopub.execute_input": "2025-01-09T19:34:58.495836Z",
          "iopub.status.idle": "2025-01-09T19:34:58.510102Z",
          "shell.execute_reply.started": "2025-01-09T19:34:58.495812Z",
          "shell.execute_reply": "2025-01-09T19:34:58.509363Z"
        },
        "id": "ghuAeMMwBsRh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature engineering"
      ],
      "metadata": {
        "id": "GpluNw2XBsRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature engineering for family size"
      ],
      "metadata": {
        "id": "ig8wZM-IBsRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Family_Size'] = train_data['Parch']+ train_data['SibSp']\n",
        "test_data['Family_Size'] = test_data['Parch']+ test_data['SibSp']\n",
        "\n",
        "train_data['Is_Alone'] = train_data['Family_Size'] == 0\n",
        "test_data['Is_Alone'] = test_data['Family_Size'] == 0\n",
        "\n",
        "train_data.sample(5 , random_state=42)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:58.511007Z",
          "iopub.execute_input": "2025-01-09T19:34:58.511328Z",
          "iopub.status.idle": "2025-01-09T19:34:58.530901Z",
          "shell.execute_reply.started": "2025-01-09T19:34:58.511296Z",
          "shell.execute_reply": "2025-01-09T19:34:58.530185Z"
        },
        "id": "8EwFra1vBsRi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "ticket prefix extration and encoding"
      ],
      "metadata": {
        "id": "M_dRhnTgBsRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prefix_extraction(string):\n",
        "    string = string.replace('/' , '').replace('.' , '')\n",
        "    # print(string)\n",
        "    parts=string.split()\n",
        "    # print(string)\n",
        "    return parts[0] if len(parts)>1 else None\n",
        "\n",
        "\n",
        "# How to apply a function on a column\n",
        "# new features creation\n",
        "train_data['Ticket_length'] = train_data.Ticket.apply(lambda x: len(x))\n",
        "test_data['Ticket_length'] = test_data.Ticket.apply(lambda x: len(x))\n",
        "\n",
        "train_data['Ticket_Prefix']=train_data.Ticket.apply(prefix_extraction)\n",
        "test_data['Ticket_Prefix']=test_data.Ticket.apply(prefix_extraction)\n",
        "# train_data=train_data.rename(columns={'Ticket' : 'Ticket_Prefix'}  )\n",
        "\n",
        "train_data"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:58.740833Z",
          "iopub.execute_input": "2025-01-09T19:34:58.741096Z",
          "iopub.status.idle": "2025-01-09T19:34:58.763916Z",
          "shell.execute_reply.started": "2025-01-09T19:34:58.741073Z",
          "shell.execute_reply": "2025-01-09T19:34:58.763113Z"
        },
        "id": "9PHAA43ABsRl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "bining features"
      ],
      "metadata": {
        "id": "J57w1TIFBsRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Fare_binning'] = pd.qcut(\n",
        "    train_data.Fare,\n",
        "    q=[0, 0.33, 0.66, 1],  # Quantiles\n",
        "    labels=['low', 'moderate', 'high']\n",
        ")\n",
        "# alternative implementation :\n",
        "# train_data['Fare_binning'] = pd.cut(\n",
        "#     train_data.Fare,\n",
        "#     bins=[0, train_data.Fare.quantile(0.33), train_data.Fare.quantile(0.66), train_data.Fare.max()],\n",
        "#     labels=['low', 'moderate', 'high']\n",
        "# )\n",
        "test_data['Fare_binning'] = pd.qcut(\n",
        "    train_data.Fare,\n",
        "    q=[0, 0.33, 0.66, 1],  # Quantiles\n",
        "    labels=['low', 'moderate', 'high']\n",
        ")\n",
        "\n",
        "train_data['Age_binning'] = pd.cut(\n",
        "    train_data.Fare,\n",
        "    bins=[0, train_data.Age.quantile(0.33), train_data.Age.quantile(0.66), train_data.Fare.max()],\n",
        "    labels=['child', 'young', 'old']\n",
        ")\n",
        "test_data['Age_binning'] = pd.cut(\n",
        "    train_data.Fare,\n",
        "    bins=[0, train_data.Age.quantile(0.33), train_data.Age.quantile(0.66), train_data.Fare.max()],\n",
        "    labels=['child', 'young', 'old']\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_data\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:58.765138Z",
          "iopub.execute_input": "2025-01-09T19:34:58.765437Z",
          "iopub.status.idle": "2025-01-09T19:34:58.794767Z",
          "shell.execute_reply.started": "2025-01-09T19:34:58.765403Z",
          "shell.execute_reply": "2025-01-09T19:34:58.794152Z"
        },
        "id": "2B7RJxBTBsRm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "0LIefOcOBsRm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name column"
      ],
      "metadata": {
        "id": "3e5gC1nTBsRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['Title'] = train_data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].replace(' ', ''))\n",
        "test_data['Title'] = test_data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].replace(' ', ''))\n",
        "print(train_data['Title'].nunique())\n",
        "print(train_data['Title'].unique())\n",
        "\n",
        "train_data.Title.replace(['Mrs' , 'Mlle' , 'Lady'],'Ms' , inplace=True)\n",
        "test_data.Title.replace(['Mrs' , 'Mlle' , 'Lady'],'Ms' , inplace=True)\n",
        "\n",
        "train_data.Title.replace(['Sir' , 'Mme'],'Mr' , inplace=True)\n",
        "test_data.Title.replace(['Sir' , 'Mme'],'Mr' , inplace=True)\n",
        "\n",
        "train_data['Title'] = train_data.Title.transform(lambda x: 'other' if x not in ['Ms' , 'Mr'] else x)\n",
        "\n",
        "train_data['Title'].value_counts()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:59.169162Z",
          "iopub.execute_input": "2025-01-09T19:34:59.169402Z",
          "iopub.status.idle": "2025-01-09T19:34:59.185519Z",
          "shell.execute_reply.started": "2025-01-09T19:34:59.169382Z",
          "shell.execute_reply": "2025-01-09T19:34:59.184642Z"
        },
        "id": "V426EVpXBsRn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoding categorical data"
      ],
      "metadata": {
        "id": "p3j6OQ9zBsRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "solution 1"
      ],
      "metadata": {
        "id": "8Tnt8SAjBsRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#map method\n",
        "train_data['Sex']=train_data['Sex'].map({'female':0 , 'male':1} )\n",
        "test_data['Sex']=test_data['Sex'].map({'female':0 , 'male':1})\n",
        "train_data.sample(3)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:59.186697Z",
          "iopub.execute_input": "2025-01-09T19:34:59.186932Z",
          "iopub.status.idle": "2025-01-09T19:34:59.208537Z",
          "shell.execute_reply.started": "2025-01-09T19:34:59.186906Z",
          "shell.execute_reply": "2025-01-09T19:34:59.207859Z"
        },
        "id": "GuRGlSPEBsR0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "solution 2"
      ],
      "metadata": {
        "id": "3NUqhGTJBsR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Columns to encode\n",
        "columns_to_encode = ['Cabin', 'Ticket_Prefix', 'Title', 'Embarked', 'Ticket' ,'Is_Alone','Fare_binning' , 'Age_binning']\n",
        "\n",
        "# Initialize OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse=False, drop='first', handle_unknown='infrequent_if_exist')\n",
        "\n",
        "# Loop through each column and apply encoding\n",
        "for column in columns_to_encode:\n",
        "    # Add an \"Unknown\" category to the training data\n",
        "    train_data[column] = train_data[column].astype(str)  # Ensure all values are strings\n",
        "    train_data[column].fillna('Unknown', inplace=True)  # Replace NaN with \"Unknown\"\n",
        "\n",
        "    # Fit and transform the training data\n",
        "    train_encoded = encoder.fit_transform(train_data[[column]])\n",
        "    train_encoded_df = pd.DataFrame(train_encoded, columns=encoder.get_feature_names_out([column]))\n",
        "\n",
        "    # Add an \"Unknown\" category to the test data\n",
        "    test_data[column] = test_data[column].astype(str)  # Ensure all values are strings\n",
        "    test_data[column].fillna('Unknown', inplace=True)  # Replace NaN with \"Unknown\"\n",
        "\n",
        "    # Transform the test data\n",
        "    test_encoded = encoder.transform(test_data[[column]])\n",
        "    test_encoded_df = pd.DataFrame(test_encoded, columns=encoder.get_feature_names_out([column]))\n",
        "\n",
        "    # Concatenate the encoded data with the original DataFrame\n",
        "    train_data = pd.concat([train_data, train_encoded_df], axis=1).drop(column, axis=1)\n",
        "    test_data = pd.concat([test_data, test_encoded_df], axis=1).drop(column, axis=1)\n",
        "\n",
        "# Display the transformed data\n",
        "print(\"Transformed Train Data:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nTransformed Test Data:\")\n",
        "print(test_data.head())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:59.210003Z",
          "iopub.execute_input": "2025-01-09T19:34:59.210214Z",
          "iopub.status.idle": "2025-01-09T19:34:59.319389Z",
          "shell.execute_reply.started": "2025-01-09T19:34:59.210196Z",
          "shell.execute_reply": "2025-01-09T19:34:59.318656Z"
        },
        "id": "YR_IltWqBsR1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train test split"
      ],
      "metadata": {
        "id": "BJBomRIGBsR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_data.drop('Survived' , axis=1)\n",
        "y = train_data['Survived']\n",
        "\n",
        "\n",
        "train_data.columns\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2 , random_state=42)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:59.320355Z",
          "iopub.execute_input": "2025-01-09T19:34:59.320673Z",
          "iopub.status.idle": "2025-01-09T19:34:59.330068Z",
          "shell.execute_reply.started": "2025-01-09T19:34:59.320647Z",
          "shell.execute_reply": "2025-01-09T19:34:59.328968Z"
        },
        "id": "ow8_9bLFBsR2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "ssc = StandardScaler()\n",
        "ssc.fit_transform(X_train.drop('Name' , axis=1))\n",
        "ssc.transform(X_test.drop('Name' , axis=1))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:59.331189Z",
          "iopub.execute_input": "2025-01-09T19:34:59.331509Z",
          "iopub.status.idle": "2025-01-09T19:34:59.36607Z",
          "shell.execute_reply.started": "2025-01-09T19:34:59.331477Z",
          "shell.execute_reply": "2025-01-09T19:34:59.365444Z"
        },
        "id": "rRYSxK1MBsR2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "outlier, skewness handling"
      ],
      "metadata": {
        "id": "ANrs2kOeBsR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X[['Parch','Fare' , 'SibSp' , 'Age' , 'Pclass']].hist(bins=50, figsize=(50, 50), layout=(5, 2), grid=False)\n",
        "plt.show()\n",
        "num_tr_data.skew()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:34:59.366838Z",
          "iopub.execute_input": "2025-01-09T19:34:59.367123Z",
          "iopub.status.idle": "2025-01-09T19:35:00.948229Z",
          "shell.execute_reply.started": "2025-01-09T19:34:59.367093Z",
          "shell.execute_reply": "2025-01-09T19:35:00.947353Z"
        },
        "id": "q3trlLuMBsR3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import boxcox\n",
        "\n",
        "# Function to handle outliers\n",
        "def outlier_handler(df):\n",
        "    for feature in df.columns:\n",
        "        Q1 = df[feature].quantile(0.25)  # First Quartile\n",
        "        Q3 = df[feature].quantile(0.75)  # 3rd Quartile\n",
        "        IQR = Q3 - Q1\n",
        "        upper_bound = Q3 + 1.5 * IQR  # Upper bound\n",
        "        lower_bound = Q1 - 1.5 * IQR  # Lower bound\n",
        "        # Clip outliers\n",
        "        df[feature] = df[feature].clip(lower_bound, upper_bound)\n",
        "    return df\n",
        "\n",
        "# Visualize the distribution of numerical features\n",
        "X_train[['Parch', 'Fare', 'SibSp', 'Age', 'Pclass']].hist(bins=50, figsize=(20, 20), layout=(5, 2), grid=False)\n",
        "plt.show()\n",
        "\n",
        "# Check skewness\n",
        "print(\"Skewness before handling:\")\n",
        "print(X_train[['Parch', 'Fare', 'SibSp', 'Age', 'Pclass']].skew())\n",
        "\n",
        "# Handle skewness using log transformation (for positive values only)\n",
        "def handle_skewness(df):\n",
        "    for feature in df.columns:\n",
        "        if df[feature].min() > 0:  # Log transformation works only for positive values\n",
        "            df[feature] = np.log1p(df[feature])  # log1p to handle zeros\n",
        "        else:\n",
        "            # Use Box-Cox transformation for features with non-positive values\n",
        "            df[feature], _ = boxcox(df[feature] + 1)  # Add 1 to handle zeros\n",
        "    return df\n",
        "\n",
        "# Apply skewness handling to X_train and X_test\n",
        "X_train[['Parch', 'Fare', 'SibSp', 'Age', 'Pclass']] = handle_skewness(X_train[['Parch', 'Fare', 'SibSp', 'Age', 'Pclass']])\n",
        "X_test[['Parch', 'Fare', 'SibSp', 'Age', 'Pclass']] = handle_skewness(X_test[['Parch', 'Fare', 'SibSp', 'Age', 'Pclass']])\n",
        "\n",
        "# Check skewness after handling\n",
        "print(\"\\nSkewness after handling:\")\n",
        "print(X_train[['Parch', 'Fare', 'SibSp', 'Age', 'Pclass']].skew())\n",
        "\n",
        "# Handle outliers using the outlier_handler function\n",
        "X_train[['Parch', 'Fare', 'SibSp', 'Age', 'Pclass']] = outlier_handler(X_train[['Parch', 'Fare', 'SibSp', 'Age', 'Pclass']])\n",
        "X_test[['Parch', 'Fare', 'SibSp', 'Age', 'Pclass']] = outlier_handler(X_test[['Parch', 'Fare', 'SibSp', 'Age', 'Pclass']])\n",
        "\n",
        "# Visualize the distribution after handling skewness and outliers\n",
        "X_train[['Parch', 'Fare', 'SibSp', 'Age', 'Pclass']].hist(bins=50, figsize=(20, 20), layout=(5, 2), grid=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:35:00.949902Z",
          "iopub.execute_input": "2025-01-09T19:35:00.950149Z",
          "iopub.status.idle": "2025-01-09T19:35:03.241528Z",
          "shell.execute_reply.started": "2025-01-09T19:35:00.950129Z",
          "shell.execute_reply": "2025-01-09T19:35:03.240275Z"
        },
        "id": "swmD6eBmBsR3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost"
      ],
      "metadata": {
        "id": "zDdupNsWBsR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Step 1: Check column types\n",
        "print(\"X_train dtypes before conversion:\")\n",
        "print(X_train.dtypes)\n",
        "\n",
        "print(\"\\nX_test dtypes before conversion:\")\n",
        "print(X_test.dtypes)\n",
        "\n",
        "# Step 2: Convert object columns to category or numeric\n",
        "for col in X_train.columns:\n",
        "    if X_train[col].dtype == 'object':  # If column is of type object\n",
        "        X_train[col] = X_train[col].astype('category')  # Convert to category\n",
        "        X_test[col] = X_test[col].astype('category')  # Convert to category\n",
        "\n",
        "# Step 3: Verify column types after conversion\n",
        "print(\"\\nX_train dtypes after conversion:\")\n",
        "print(X_train.dtypes)\n",
        "\n",
        "print(\"\\nX_test dtypes after conversion:\")\n",
        "print(X_test.dtypes)\n",
        "\n",
        "# Step 4: Initialize XGBoost Classifier with enable_categorical=True\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=500,  # Number of boosting rounds\n",
        "    max_depth=5,       # Maximum depth of a tree\n",
        "    learning_rate=0.1, # Learning rate\n",
        "    objective='binary:logistic',  # For binary classification\n",
        "    random_state=42,\n",
        "    enable_categorical=True  # Enable support for categorical features\n",
        ")\n",
        "\n",
        "# Step 5: Train the model\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Make predictions\n",
        "y_train_pred = xgb_model.predict(X_train)\n",
        "y_test_pred = xgb_model.predict(X_test)\n",
        "\n",
        "# Step 7: Evaluate the model\n",
        "# Training set performance\n",
        "print(\"Training Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
        "print(\"Training Classification Report:\\n\", classification_report(y_train, y_train_pred))\n",
        "print(\"Training Confusion Matrix:\\n\", confusion_matrix(y_train, y_train_pred))\n",
        "\n",
        "# Test set performance\n",
        "print(\"\\nTest Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(\"Test Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
        "print(\"Test Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "# Step 8: Feature Importance\n",
        "feature_importance = xgb_model.feature_importances_\n",
        "feature_names = X_train.columns\n",
        "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(importance_df)\n",
        "\n",
        "# Step 9: Visualize Feature Importance\n",
        "importance_df.plot(kind='bar', x='Feature', y='Importance', figsize=(10, 6), legend=False)\n",
        "plt.title('Feature Importance')\n",
        "plt.ylabel('Importance Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-09T19:37:07.888866Z",
          "iopub.execute_input": "2025-01-09T19:37:07.889153Z",
          "iopub.status.idle": "2025-01-09T19:37:14.193074Z",
          "shell.execute_reply.started": "2025-01-09T19:37:07.889129Z",
          "shell.execute_reply": "2025-01-09T19:37:14.192261Z"
        },
        "id": "YKK9AgTmBsR5"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}