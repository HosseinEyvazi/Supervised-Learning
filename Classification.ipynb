{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2nsW0CcrKNfSI4Nlnof5R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HosseinEyvazi/Supervised-Learning/blob/main/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification VS Clustering(unsupervised)\n",
        "unsupervised has not got a label -> therefore we have to segment (or ...) datas"
      ],
      "metadata": {
        "id": "yHSDvWGp8ctQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification\n",
        "Tasks :\n",
        "*   Binary classification (one-class classification)\n",
        "*   Multi-class classification\n",
        "\n"
      ],
      "metadata": {
        "id": "QqiFAN3V83jM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression\n",
        "\n",
        "## Overview\n",
        "- Logistic Regression is **a regression model used for classification tasks**.\n",
        "- It applies a **linear regression** followed by a **Sigmoid function** to predict probabilities.\n",
        "\n",
        "## Loss Function\n",
        "- Logistic Regression aims to minimize the **Cross-Entropy Loss** to optimize predictions.\n",
        "\n",
        "## Multi-Class Classification\n",
        "- Logistic Regression, by default, is designed for **binary classification** (one-vs-one).  \n",
        "- To extend it for **multi-class classification**, we use techniques like:\n",
        "  1. **One-vs-Rest (OvR):** Train one binary classifier per class.\n",
        "  2. **Softmax Function:** Generalizes the sigmoid function for multi-class problems.\n",
        "\n",
        "### Loss Function for Multi-Class\n",
        "- The loss function for multi-class classification is based on the **Categorical Cross-Entropy**, which minimizes the error across all classes.\n",
        "\n",
        "### Important Note About softmax, OVO ,OVA\n",
        "- **Softmax**: A function to convert logits into probabilities, often used with cross-entropy loss.\n",
        "- **OVO (One-Vs-One)**: A multi-class classification strategy using pairwise binary classifiers.\n",
        "- **OVR/OVA (One-Vs-Rest/One-Vs-All)**: A multi-class classification strategy using one binary classifier per class.\n",
        "- **Cross-Entropy**: A loss function used to measure the difference between predicted and true probability distributions.\n",
        "\n",
        "### (OVO)** and **One-Vs-All (OVA)** classification strategies:\n",
        "\n",
        "| **Aspect**                      | **One-Vs-One (OVO)**                                        | **One-Vs-All (OVA)**                                      |\n",
        "|---------------------------------|-------------------------------------------------------------|-----------------------------------------------------------|\n",
        "| **Definition**                  | Trains a separate classifier for every pair of classes.     | Trains a separate classifier for each class against all others. |\n",
        "| **Number of Classifiers**       | \\(\\frac{n(n-1)}{2}\\) classifiers for \\(n\\) classes.         | \\(n\\) classifiers for \\(n\\) classes.                     |\n",
        "| **Computational Complexity**    | Higher, especially as the number of classes increases.      | Lower and scales linearly with the number of classes.      |\n",
        "| **Training Time**               | Longer due to the larger number of classifiers.             | Generally faster since fewer classifiers are trained.      |\n",
        "| **Prediction Time**             | Can be slower due to aggregating results from multiple classifiers. | Typically faster as only one classifier per class is evaluated. |\n",
        "| **Suitability**                 | Best for problems with a smaller number of classes.         | Suitable for problems with a large number of classes.      |\n",
        "| **Performance with Imbalanced Data** | Often handles imbalanced data better since each classifier deals with balanced pairwise classes. | May struggle with imbalanced data as some classifiers have many negative samples. |\n",
        "| **Handling of Overlapping Classes** | Can better distinguish between specific pairs of overlapping classes. | May have difficulty distinguishing classes with significant overlap. |\n",
        "| **Voting Mechanism**            | Uses majority voting from all pairwise classifiers to decide the final class. | Selects the class with the highest confidence score from all classifiers. |\n",
        "| **Advantages**                  | - Better performance in multi-class scenarios.<br>- Effective with overlapping classes.<br>- Can handle imbalanced data better. | - Simpler and faster to implement.<br>- Requires fewer classifiers.<br>- Easier to interpret individual classifier outputs. |\n",
        "| **Disadvantages**               | - Computationally intensive with many classes.<br>- More complex to aggregate results. | - May not perform as well with highly overlapping classes.<br>- Potential issues with class imbalance. |\n",
        "\n",
        "\n",
        "## References\n",
        "- Learn more about extending Logistic Regression for multi-class classification:  \n",
        "  [Multi-Class Logistic Regression](https://chatgpt.com/share/67766d57-07c4-800f-addf-a2fad1c559f0)\n"
      ],
      "metadata": {
        "id": "EYaDcQONgKRV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Tree, Random Forest, XGBoost, and LightGBM Theory\n",
        "\n",
        "## 1. Decision Tree\n",
        "\n",
        "### **What is a Decision Tree?**\n",
        "A **Decision Tree** is a supervised learning algorithm used for both **classification** and **regression** tasks. It models decisions and their possible consequences as a tree-like structure.\n",
        "\n",
        "### **How It Works**\n",
        "- **Nodes:**\n",
        "  - **Root Node:** The topmost node representing the entire dataset.\n",
        "  - **Decision Nodes:** Nodes that split the data based on feature values.\n",
        "  - **Leaf Nodes:** Terminal nodes that provide the final output or prediction.\n",
        "  \n",
        "- **Splitting Criteria:**\n",
        "  - **Classification:** Uses metrics like **Gini Impurity**, **Entropy** (Information Gain).\n",
        "  - **Regression:** Uses **Mean Squared Error (MSE)** or **Mean Absolute Error (MAE)**.\n",
        "\n",
        "- **Building the Tree:**\n",
        "  1. Start at the root node with the entire dataset.\n",
        "  2. Select the best feature to split the data based on the chosen criteria.\n",
        "  3. Repeat the process recursively for each child node until stopping conditions are met (e.g., maximum depth, minimum samples).\n",
        "\n",
        "### **Advantages**\n",
        "- **Interpretability:** Easy to visualize and understand.\n",
        "- **No Need for Feature Scaling:** Works with both numerical and categorical data.\n",
        "- **Handles Non-linear Relationships:** Can capture complex patterns.\n",
        "\n",
        "### **Disadvantages**\n",
        "- **Overfitting:** Prone to creating overly complex trees that don't generalize well.\n",
        "- **Bias Towards Dominant Features:** Can favor features with more levels.\n",
        "- **Instability:** Small changes in data can lead to different tree structures.\n",
        "\n",
        "### **Use Cases**\n",
        "- Customer segmentation\n",
        "- Risk assessment\n",
        "- Medical diagnosis \\\n",
        " [an example of Decision Tree Regressor](https://chatgpt.com/share/67a5de96-9cb4-8000-b3a3-7a1b1873054a)\n",
        "---\n",
        "\n",
        "## 2. Random Forest\n",
        "\n",
        "### **What is a Random Forest?**\n",
        "**Random Forest** is an ensemble learning method that builds multiple **Decision Trees** and merges their results to improve **classification** and **regression** accuracy.\n",
        "\n",
        "### **How It Works**\n",
        "- **Bagging (Bootstrap Aggregating):**\n",
        "  - Generate multiple subsets of the original dataset using random sampling WITH REPLACEMENT.\n",
        "  \n",
        "- **Tree Construction:**\n",
        "  - Build a Decision Tree for each subset.\n",
        "  - At each split, randomly select a subset of features to consider, enhancing diversity among trees.\n",
        "  \n",
        "- **Aggregation:**\n",
        "  - **Classification:** Majority voting across all trees.\n",
        "  - **Regression:** Averaging the predictions of all trees.\n",
        "\n",
        "### **Advantages**\n",
        "- **Reduces Overfitting:** Averaging multiple trees mitigates overfitting inherent in individual Decision Trees.\n",
        "- **Handles High Dimensionality:** Effective with large numbers of features.\n",
        "- **Robust to Noise:** Can manage noisy data and outliers.\n",
        "\n",
        "### **Disadvantages**\n",
        "- **Less Interpretable:** Difficult to visualize compared to a single Decision Tree.\n",
        "- **Computationally Intensive:** Requires more resources to build and predict.\n",
        "- **Slower Predictions:** Aggregating multiple trees can be time-consuming.\n",
        "\n",
        "### **Use Cases**\n",
        "- Feature selection\n",
        "- Predictive analytics\n",
        "- Financial forecasting\n",
        "[an example of Random Forest Regressor](https://chatgpt.com/share/67a5de96-9cb4-8000-b3a3-7a1b1873054a)\n",
        "---\n",
        "\n",
        "## 3. XGBoost\n",
        "\n",
        "### **What is XGBoost?**\n",
        "**XGBoost** (**Extreme Gradient Boosting**) is a powerful and efficient implementation of the **Gradient Boosting** framework, designed for speed and performance in machine learning competitions.\n",
        "\n",
        "### **How It Works**\n",
        "- **Gradient Boosting:**\n",
        "  - Builds models sequentially, where each new model attempts to correct the errors of the previous ones.\n",
        "  - Optimizes a loss function using gradient descent.\n",
        "  \n",
        "- **Regularization:**\n",
        "  - Incorporates **L1** and **L2** regularization to prevent overfitting.\n",
        "  \n",
        "- **Tree Pruning:**\n",
        "  - Uses **Max Depth** and **Min Child Weight** to control tree complexity.\n",
        "  \n",
        "- **Handling Missing Values:**\n",
        "  - Automatically learns the best direction to handle missing data.\n",
        "  \n",
        "- **Parallel Processing:**\n",
        "  - Efficiently utilizes hardware by parallelizing tree construction.\n",
        "\n",
        "### **Advantages**\n",
        "- **High Performance:** Often outperforms other algorithms in accuracy.\n",
        "- **Flexibility:** Supports various objective functions for classification and regression.\n",
        "- **Feature Importance:** Provides insights into feature relevance.\n",
        "- **Handles Missing Data:** Automatically manages missing values without imputation.\n",
        "\n",
        "### **Disadvantages**\n",
        "- **Complexity:** More parameters to tune, which can be challenging.\n",
        "- **Computationally Intensive:** Can be resource-heavy with large datasets.\n",
        "- **Less Interpretable:** Harder to interpret compared to simpler models.\n",
        "\n",
        "### **Use Cases**\n",
        "- Ranking systems\n",
        "- Click-through rate prediction\n",
        "- Fraud detection\n",
        "\n",
        "---\n",
        "\n",
        "## 4. LightGBM\n",
        "\n",
        "### **What is LightGBM?**\n",
        "**LightGBM** (**Light Gradient Boosting Machine**) is a gradient boosting framework that uses **tree-based learning algorithms**. It is designed to be highly efficient, scalable, and capable of handling large-scale data.\n",
        "\n",
        "### **How It Works**\n",
        "- **Gradient Boosting:**\n",
        "  - Similar to XGBoost, builds models sequentially to minimize the loss function.\n",
        "  \n",
        "- **Leaf-wise Growth:**\n",
        "  - Grows trees by selecting the leaf with the maximum loss to split, leading to deeper and more complex trees.\n",
        "  \n",
        "- **Histogram-based Decision Making:**\n",
        "  - Bins continuous features into discrete bins to speed up training and reduce memory usage.\n",
        "  \n",
        "- **Exclusive Feature Bundling (EFB):**\n",
        "  - Combines mutually exclusive features to reduce the dimensionality.\n",
        "  \n",
        "- **Support for Categorical Features:**\n",
        "  - Directly handles categorical features without the need for one-hot encoding.\n",
        "\n",
        "### **Advantages**\n",
        "- **Speed and Efficiency:** Faster training and lower memory consumption compared to other boosting algorithms.\n",
        "- **Handles Large Datasets:** Scales well with large volumes of data.\n",
        "- **High Accuracy:** Comparable to or better than XGBoost in many cases.\n",
        "- **Better Handling of Categorical Features:** Simplifies preprocessing steps.\n",
        "\n",
        "### **Disadvantages**\n",
        "- **Overfitting Risk:** Leaf-wise growth can lead to overfitting if not properly regularized.\n",
        "- **Complexity:** Requires careful tuning of parameters to achieve optimal performance.\n",
        "- **Less Interpretable:** Similar to other boosting methods, harder to interpret than simpler models.\n",
        "\n",
        "### **Use Cases**\n",
        "- Real-time predictions\n",
        "- Large-scale classification and regression tasks\n",
        "- Recommender systems\n",
        "\n",
        "---\n",
        "\n",
        "# Summary\n",
        "\n",
        "- **Decision Trees** are intuitive models ideal for understanding data but prone to overfitting.\n",
        "- **Random Forests** enhance Decision Trees by ensembling multiple trees to improve accuracy and robustness.\n",
        "- **XGBoost** offers high performance through optimized gradient boosting with regularization and parallel processing.\n",
        "- **LightGBM** provides efficient and scalable gradient boosting with advanced techniques like leaf-wise growth and histogram-based decision making.\n",
        "\n",
        "Each algorithm has its strengths and is chosen based on the specific requirements of the task, such as dataset size, computational resources, and the need for interpretability.\n",
        "\n",
        "[Learn more](https://chatgpt.com/share/6784f9ce-186c-8000-a69b-853caa17827d)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ucihzHGNuCX3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Decision Tree Criteria**\n",
        "\n",
        "## **Introduction**\n",
        "Decision Trees are powerful models used in classification and regression. A key part of their learning process is choosing the best way to split the data. This is done using criteria that measure how \"pure\" or \"impure\" a node is. The two main criteria used are **Gini impurity** and **Entropy (Information Gain)**.\n",
        "\n",
        "---\n",
        "\n",
        "## **1. Gini Impurity** (Used in CART Algorithm)\n",
        "### **What is it?**\n",
        "Gini impurity measures how mixed the classes are in a node. Lower Gini means purer groups.\n",
        "\n",
        "### **Formula**\n",
        "Gini = 1 - (p1^2 + p2^2 + ... + pn^2)\n",
        "\n",
        "Where:\n",
        "- `p1, p2, ..., pn` are the proportions of each class in the node.\n",
        "\n",
        "### **How does it work?**\n",
        "- If all samples in a node belong to the same class, Gini impurity is **0** (perfectly pure).\n",
        "- If the classes are evenly mixed, Gini impurity is higher.\n",
        "- The tree **chooses the split** that results in the **lowest Gini impurity** after the split.\n",
        "\n",
        "### **Key Takeaway:**\n",
        "Gini impurity is **fast** and works well in most cases.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Entropy & Information Gain** (Used in ID3, C4.5)\n",
        "### **What is Entropy?**\n",
        "Entropy measures the uncertainty or disorder in a node. Higher entropy means more randomness.\n",
        "\n",
        "### **Formula **\n",
        "Entropy = - (p1 * log2(p1) + p2 * log2(p2) + ... + pn * log2(pn))\n",
        "Where:\n",
        "- `p1, p2, ..., pn` are the proportions of each class in the node.\n",
        "- `log2` is the logarithm with base 2.\n",
        "\n",
        "### **How does Information Gain work?**\n",
        "- The tree calculates **entropy before and after a split**.\n",
        "- It finds how much **uncertainty is reduced** after the split (this is called **Information Gain**).\n",
        "\n",
        "### **Information Gain Formula**\n",
        "Information Gain = Entropy(before) - Weighted Entropy(after)\n",
        "\n",
        "- The tree chooses the split that **maximizes Information Gain**.\n",
        "\n",
        "### **Key Takeaway:**\n",
        "Entropy is **more precise** but slightly **slower** than Gini.\n",
        "\n",
        "---\n",
        "\n",
        "## **Gini vs. Entropy: Which One to Use?**\n",
        "\n",
        "| Criterion  | Speed  | Best For |\n",
        "|------------|--------|-----------|\n",
        "| **Gini**   | Faster  | Most cases (default in sklearn) |\n",
        "| **Entropy** | Slower  | When you want a more precise split |\n",
        "\n",
        "ðŸ‘‰ **Tip:** If youâ€™re unsure, just go with **Gini impurity**! ðŸš€\n",
        "\n",
        "---\n",
        "\n",
        "## **Conclusion**\n",
        "Decision Trees automatically select the best feature and split using either **Gini impurity** or **Entropy**. Both methods help the tree learn better and make smarter decisions! ðŸŽ¯\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "a2J_DP7lxCWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model performance\n",
        "In regression : MSE , MAE , RMSE , ...   \n",
        "In clustering : NMI , ARI , Silhouette , Rand , ...\n",
        "In classification : [methods](https://chatgpt.com/share/67767aaf-fa10-800f-8a14-e1dbbc5885c1)\n",
        "\n",
        "\n",
        "\n",
        "Note : [That is why](https://chatgpt.com/share/677676af-0bc0-800f-b610-51c8c37fe0ba) False Negative , Flase positve importance are not same. \\\n",
        "Confusion matrix : is matrix to show true positive and ... with more details\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ISr-87kKuf9P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DEQdw4Z8Zh3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.svm import SVC # support vector classifier\n",
        "from sklearn.svm import SVR # support vector regressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler , StandardScaler\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.metrics import classification_report , confusion_matrix , recall_score , f1_score\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = load_breast_cancer().data\n",
        "y = load_breast_cancer().target\n",
        "\n",
        "X = pd.DataFrame(X , columns = load_breast_cancer().feature_names )\n",
        "y = pd.DataFrame(y , columns = ['target'] )\n"
      ],
      "metadata": {
        "id": "iwiU__IdGSXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X ,y , random_state=42 , test_size=.10)"
      ],
      "metadata": {
        "id": "zpHHCph2HsOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ssc = StandardScaler()\n",
        "X_train = ssc.fit_transform(X_train)\n",
        "X_test = ssc.transform(X_test)\n"
      ],
      "metadata": {
        "id": "y77V4FgQIbkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install --upgrade scikit-learn xgboost\n",
        "\n",
        "xgbc = RandomForestClassifier()\n",
        "param_distributions = {'n_estimators':range(20,200) , 'max_depth':range(20,500)}\n",
        "rscv = RandomizedSearchCV(xgbc , param_distributions=param_distributions , cv=50)\n",
        "rscv.fit(X_train , y_train)\n",
        "# xgbc.fit(X_train , y_train)"
      ],
      "metadata": {
        "id": "is6zHd9JJV5Z",
        "outputId": "b72a01d5-9aa3-430a-9c35-f85750a43823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=50, estimator=RandomForestClassifier(),\n",
              "                   param_distributions={'max_depth': range(20, 500),\n",
              "                                        'n_estimators': range(20, 200)})"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"â–¸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"â–¾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=50, estimator=RandomForestClassifier(),\n",
              "                   param_distributions={&#x27;max_depth&#x27;: range(20, 500),\n",
              "                                        &#x27;n_estimators&#x27;: range(20, 200)})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomizedSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=50, estimator=RandomForestClassifier(),\n",
              "                   param_distributions={&#x27;max_depth&#x27;: range(20, 500),\n",
              "                                        &#x27;n_estimators&#x27;: range(20, 200)})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: RandomForestClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=112, n_estimators=72)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=112, n_estimators=72)</pre></div> </div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rscv.predict(X_test)\n",
        "f1_score(y_test , y_pred)"
      ],
      "metadata": {
        "id": "jddXFtlQQOQr",
        "outputId": "c6d87ff3-3182-49c5-98b6-be32fe5d572f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.975"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "f1 score is avg of precision and recall that is why this is an imoprtant score"
      ],
      "metadata": {
        "id": "rCRHZgh_SWZD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support vector machine classification"
      ],
      "metadata": {
        "id": "BiRwpFVw7Okb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "svc = SVC()\n",
        "param_distributions = {\n",
        "    'C': np.logspace(-3, 3, 7),\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': np.logspace(-3, 3, 7),\n",
        "    'degree': [2, 3, 4],\n",
        "    'coef0': np.linspace(-1, 1, 5)\n",
        "}\n",
        "rscv_svc = RandomizedSearchCV(svc, param_distributions=param_distributions, cv=20 , random_state=42) # use lower cv values for faster training, it takes way too long with cv=50\n",
        "rscv_svc.fit(X_train, y_train)\n",
        "\n",
        "y_pred_svc = rscv_svc.predict(X_test)\n",
        "f1_svc = f1_score(y_test, y_pred_svc)\n",
        "print(f\"SVC F1 Score: {f1_svc}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "QyqlrFYwUVbK",
        "outputId": "59845c91-7be2-46d1-a8e0-4aedcbb829a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC F1 Score: 0.975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LogisticRegression"
      ],
      "metadata": {
        "id": "8WjRT-7O7IKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "lr = LogisticRegression()\n",
        "param_distributions = {\n",
        "    'C': np.logspace(-3, 3, 20),\n",
        "    'penalty': ['l1', 'l2' , 'elasticnet' , 'None'],\n",
        "    'class_weight': [None, 'balanced'],\n",
        "    'solver': ['liblinear', 'saga' ,'sag'],\n",
        "}\n",
        "\n",
        "rscv_lr = RandomizedSearchCV(lr, param_distributions=param_distributions, cv=20 , random_state=42) # use lower cv values for faster training, it takes way too long with cv=50\n",
        "rscv_lr.fit(X_train, y_train)\n",
        "\n",
        "y_pred_lr = rscv_lr.predict(X_test)\n",
        "f1_lr = f1_score(y_test, y_pred_lr)\n",
        "classification_report(y_test , y_pred_lr)\n",
        "print(f\"Logistic Regression F1 Score: {f1_lr}\")"
      ],
      "metadata": {
        "id": "VU-iwlQu7GsI",
        "outputId": "63d7b6c9-6027-465e-c076-af188a1ee78a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression F1 Score: 0.9876543209876543\n"
          ]
        }
      ]
    }
  ]
}